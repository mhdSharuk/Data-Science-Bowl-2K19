{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows',None)\npd.set_option('display.max_columns', None)\nimport datetime\nimport catboost\nfrom catboost import CatBoostClassifier,Pool\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nimport os\nimport random\nimport itertools\nimport json\nimport pprint\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold,GroupKFold\nfrom sklearn.metrics import confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if(len(submission['installation_id'])>=1000):\n    submission.to_csv('submission.csv',index=False)\n    exit(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def qwk(a1, a2, max_rat=3):\n    assert(len(a1) == len(a2))\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spec(value,*args):\n    i= specs[specs['event_id'] == value].index.values[-1]\n    print('Index :',i)\n    print('Event_code :',train[train['event_id'] == value]['event_code'].unique()[-1])\n    for arg in args:\n        if(arg == 'info'):\n         print(specs[arg][i])\n        elif(arg == 'args'):\n         print(pprint.pprint(json.loads(specs[arg][i])))\n        else:\n         print('Nothing')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def event(value):\n    i = train[train['event_id'] == value].index.values[-1]\n    print(pprint.pprint(json.loads(train['event_data'][i])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_game_feature(df,data):\n    g0_d = dict(df[df['type'] == 'Game'].groupby('installation_id')['type'].value_counts())\n    g0 = {}\n    for (k,i),v in g0_d.items():\n        g0[k] = v\n    del g0_d\n    df['G0'] = df['installation_id'].map(g0)\n    df['G0'].fillna(0,inplace=True)\n\n    g1_d = dict(df[(df['event_code'] == 4020) & (df['type'] == 'Game')].groupby('installation_id')['event_code'].value_counts())\n    g1 = {}\n    for (k,i),v in g1_d.items():\n        g1[k] = v\n    del g1_d\n    df['G1'] = df['installation_id'].map(g1)\n    df['G1'].fillna(0,inplace=True)\n    del g1\n    \n    df['contains_true'] = df[(df['event_code'] == 4020) & (df['type'] == 'Game')]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')>= 0) else 0)\n    g2 = dict(df[df['event_code'] == 4020].groupby('installation_id')['contains_true'].sum())\n    df['G2'] = df['installation_id'].map(g2)\n    df['G2'].fillna(0,inplace=True)\n    for c in ['contains_true']:\n        df.pop(c)\n        \n    df['G3'] = df['G2'] / df['G1']\n    df['G3'] = df['G3'].map(lambda x:3 if(x == 1.0) else(2 if((x >= 0.5) & (x <1.0)) else (1 if((x>0.0) &  (x<0.5)) else 0)))\n    df['G3'].fillna(0,inplace=True)\n    \n    i = 4\n    for d in tqdm(data):\n        g_attempt_d = dict(df[(df['type'] == 'Game') & (df['event_code'] == 4020) & (df['title'] == d)].groupby('installation_id')['title'].value_counts())\n        g_attempt = {}\n        for (k,z),v in g_attempt_d.items():\n            g_attempt[k] = v\n\n        df[f'G{i}_attempt'] = df['installation_id'].map(g_attempt)\n        df[f'G{i}_attempt'].fillna(0,inplace=True)\n\n        df['contains_true'] = df[(df['type'] == 'Game') & (df['event_code'] == 4020) & (df['title'] == d)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')>=0) else 0)\n        g = dict(df.groupby('installation_id')['contains_true'].sum())\n        df[f'G{i}_correct'] = df['installation_id'].map(g)\n        df[f'G{i}_correct'].fillna(0,inplace=True)\n\n        df[f'G{i}_accuracy'] = df[f'G{i}_correct'] / df[f'G{i}_attempt']\n        df[f'G{i}_accuracy'] = df[f'G{i}_accuracy'].map(lambda x:3 if(x == 1.0) else(2 if((x >= 0.5) & (x <1.0)) else (1 if((x>0.0) &  (x<0.5)) else 0)))\n        df[f'G{i}_accuracy'].fillna(0,inplace=True)\n\n        for c in ['contains_true',f'G{i}_attempt']:\n            df.pop(c)\n            \n        i = i + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_attempted_assessment_results(df,data):\n    if(data == 'train'):\n        df = df[(df['type'] == 'Assessment') & (((df['event_code'] == 4100) & (df['title'] != 'Bird Measurer (Assessment)')) | ((df['event_code'] == 4110) & (df['title'] == 'Bird Measurer (Assessment)')))]\n    else:\n        df =  df[(df['type'] == 'Assessment') &  ((df['event_count'] == 1) | ((df['event_code'] == 4100) & (df['title'] != 'Bird Measurer (Assessment)')) | ((df['event_code'] == 4110) & (df['title'] == 'Bird Measurer (Assessment)')))]\n    session_count = df['game_session'].value_counts().to_dict()\n    df['assessment_attempt_count'] = df['game_session'].map(session_count)\n\n    df['contains_true_assessment'] = df['event_data'].map(lambda x: True if (x.find('\"correct\":true')>=0) else False)\n\n    change_value = {\n        True : 1,\n        False : 0\n    }\n    df['contains_true_assessment'] = df['contains_true_assessment'].map(change_value)\n\n    correct_attempt = dict(df.groupby('game_session',sort=False)['contains_true_assessment'].sum())\n    df['contains_true_assessment_count'] = df['game_session'].map(correct_attempt)\n\n    for c in ['contains_true_assessment']:\n        df.pop(c)\n\n    df['accumulated_accuracy'] = np.where((df['contains_true_assessment_count'] == 0),0,(df['contains_true_assessment_count']/df['assessment_attempt_count']))\n\n    df.loc[(df['type'] == 'Assessment'), 'accuracy_group'] = 0\n    df.loc[(df['accumulated_accuracy'] == 1) & (df['type'] == 'Assessment'), 'accuracy_group'] = 3\n    df.loc[(df['accumulated_accuracy'] == 0.5) & (df['type'] == 'Assessment'), 'accuracy_group'] = 2\n    df.loc[(df['accumulated_accuracy'] < 0.5) & (df['accumulated_accuracy'] > 0) & (df['assessment_attempt_count'] > 0) & (df['type'] == 'Assessment'), 'accuracy_group'] = 1\n\n    df.rename(columns = {'contains_true_assessment_count': 'num_correct',\n                            'accumulated_accuracy':'accuracy',\n                            'assessment_attempt_count': 'total_attempt'},inplace=True)\n    df = df.drop_duplicates(subset = 'game_session',keep = 'last')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_validation_data(df,num_samples,random_state):\n    validation_data = df[(df['type'] == 'Assessment') & (((df['event_code'] == 4100) & (df['title'] != 'Bird Measurer (Assessment)')) | ((df['event_code'] == 4110) & (df['title'] == 'Bird Measurer (Assessment)')))]\n    validation_data.drop_duplicates(subset = 'game_session',keep = 'last',inplace=True)\n    if(isinstance(num_samples,float)):\n            validation_data = validation_data.sample(frac = num_samples,random_state = random_state)\n            print(validation_data.shape)\n    else:\n            validation_data = validation_data.sample(n = num_samples,random_state = random_state)\n            print(validation_data.shape)\n    return validation_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df):\n    clip_features = ['num_clip_watched']\n    game_features = ['num_unique_games','total_game_actions','total_duration_spend_for_game','total_game_attempts','total_correct_attempts','last_game_played_accuracy','gaming_accuracy']\n    activity_features = []\n    total_data = {}\n\n    for i,install_id in tqdm(df.groupby('installation_id',sort=False)):\n\n        clip_data = {eve : 0 for eve in clip_features}\n        game_data = {eve : 0 for eve in game_features}\n        activity_data = {}\n        event_code_count = {eve : 0 for eve in list_of_event_code}\n\n        for j,session in install_id.groupby('game_session',sort=False):\n\n            session_type = session['type'].iloc[0]\n            session_title = session['title'].iloc[0]\n\n            if((session_type == 'Clip')):\n                clip_data['num_clip_watched'] += 1\n\n            elif(session_type == 'Game'):\n                game_data['num_unique_games'] += 1\n                game_data['total_game_actions'] += session['event_code'].count()\n                game_data['total_duration_spend_for_game'] += int(session['game_time'].iloc[-1]/1000)\n                game_data['total_game_attempts'] += session[session['event_code'] == 4020]['event_code'].count()\n                game_data['total_correct_attempts'] += session[session['event_code'] == 4020]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true') >= 0) else 0).sum()\n                game_data['gaming_accuracy'] += round((game_data['total_correct_attempts']/game_data['total_game_attempts']),3)\n                game_data['last_game_played_accuracy'] = round(game_data['total_correct_attempts'] / game_data['total_game_attempts'],3) if(game_data['total_game_attempts']>0) else 0\n            elif(session_type == 'Activity'):\n                pass\n            elif(session_type == 'Assessment'):\n                #game_preprocessing\n\n\n                #Activity preprocessing\n\n\n                #Clip preprocessing\n\n\n\n                total_data[j] = {}\n                total_data[j].update(clip_data)\n                total_data[j].update(activity_data)\n                total_data[j].update(game_data)\n\n                clip_data = {eve : 0 for eve in clip_features}\n                game_data = {eve : 0 for eve in game_features}\n                activity_data = {}\n    return total_data","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\ntrain = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assessment_id = list(train[train['type'] == 'Assessment']['installation_id'].unique())\ntrain = train.loc[train['installation_id'].isin(assessment_id)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.reset_index(drop=False)\ntrain.drop(columns = ['index'],axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_event_code = set(train['event_code'].unique()).union(set(test['event_code'].unique()))\nlist_of_event_code = list(list_of_event_code)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_game = train[(train['type'] == 'Game') | (train['type'] == 'Assessment')]\ntrain_game = train_game.reset_index(drop=False)\ntrain_game.drop(columns = ['index'],axis = 1, inplace = True)\n\ntrain_activity = train[(train['type'] == 'Assessment') | (train['type'] == 'Activity')]\ntrain_activity = train_activity.reset_index(drop=False)\ntrain_activity.drop(columns = ['index'],axis = 1, inplace = True)\n\ntrain_clip = train[(train['type'] == 'Assessment') | (train['type'] == 'Clip')]\ntrain_clip = train_clip.reset_index(drop=False)\ntrain_clip.drop(columns = ['index'],axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\nactivities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n\ntrain['title'] = train['title'].map(activities_map)\ntest['title'] = test['title'].map(activities_map)\ntrain_labels['title'] = train_labels['title'].map(activities_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dict = get_features(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dict = get_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in tqdm(['event_id','game_session','installation_id','event_code','event_data','event_count','type','timestamp','world']):\n    for df in [train,test]:\n        df.pop(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train.drop(columns=['accuracy_group'],axis=1)\ny = train['accuracy_group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_classifier():\n    clf = CatBoostClassifier(\n                               loss_function='MultiClass',\n                               task_type=\"CPU\",\n                               learning_rate=0.01,\n                               iterations=100,\n                               od_type=\"Iter\",\n                               early_stopping_rounds=50,\n                               random_seed=2019,\n                               colsample_bylevel=0.87,\n                               eval_metric='Kappa',\n                              )\n        \n    return clf\noof = np.zeros(len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(x))\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\n\n\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(x, y)):\n    \n    print(f'Training on fold {fold+1}')\n    clf = make_classifier()\n    clf.fit(x.loc[trn_idx], y.loc[trn_idx], eval_set=(x.loc[test_idx], y.loc[test_idx]),\n                          use_best_model=True, verbose=500)\n    \n    oof[test_idx] = clf.predict(x.loc[test_idx]).reshape(len(test_idx))\n    print('OOF QWK:', qwk(y, oof))\n    \nprint('-' * 30)\nprint('OOF QWK:', qwk(y, oof))\nprint('-' * 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Garbage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = train.columns.tolist()\ncols.remove('installation_id')\nfor i ,data in train.groupby('installation_id',sort=False):\n    new_data = data[cols]\n    new_data['installation_id'] = i\n    break\nnew_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df:pd.DataFrame(),which):\n    \n    new_df_list_values = []\n    event_code_count_dict = {eve : 0 for eve in list_of_event_code}\n    new_df_dict = {}\n        \n    df = df.reset_index(drop= False)\n    df.drop(columns=['index'],axis=1,inplace=True)\n    \n    for i,data in tqdm(df.groupby('installation_id',sort=False)):\n        print(i)\n        new_data = data[df.columns.tolist()]\n        new_data['installation_id'] = i\n        \n        new_data = new_data.reset_index(drop= False)\n        new_data.drop(columns=['index'],axis=1,inplace=True)\n        \n        a1 = new_data[new_data['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'first').index.tolist()\n        a2 = new_data[new_data['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'last').index.tolist()\n\n        a = []\n        a.append(0)\n        print(a2)\n        for i in range(len(a2)):\n            a.append(a2[i])\n            a.append(a2[i]+1)\n        a.pop(len(a)-1)\n        print(a)\n\n        for i in range(0,len(a),2):\n            print(a[i] , 'to' , a[i+1])\n            new_df = data.iloc[a[i]:a[i+1]+1,:]\n            g_session = new_df[new_df['type'] == 'Assessment']['game_session'].unique()[-1]\n            print(g_session)\n            new_df_dict[g_session] = {}\n            new_df_dict[g_session]['num_game_session'] = new_df['game_session'].nunique()\n            new_df_dict[g_session]['num_event_id'] = new_df['event_id'].nunique()\n            new_df_dict[g_session]['num_actions_before_assessment'] = len(new_df['event_code'])\n            new_df_dict[g_session][f'num_unique_{which}'] = new_df[new_df['type'] == which]['title'].nunique()\n            if(which == 'Game'):\n                new_df_dict[g_session]['game_attempts'] = new_df[new_df['event_code'] == 4020]['event_code'].count()\n                new_df_dict[g_session]['mean_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].mean()\n                new_df_dict[g_session]['max_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].max()\n                new_df_dict[g_session]['min_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].min()\n                new_df_dict[g_session]['std_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].std()\n                new_df['gaming_accuracy'] = new_df[(new_df['type'] == 'Game') & (new_df['event_code'] == 4020)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')) else 0)\n                new_df['gaming_accuracy'].fillna(0,inplace=True)\n                new_df_dict[g_session]['gaming_accuracy'] = new_df['gaming_accuracy'].sum()/new_df_dict[g_session]['game_attempts']\n            elif(which == 'Activity'):\n                new_df_dict[g_session]['Activity actions'] = new_df[new_df['type'] == 'Activity']['event_id'].count()\n\n            for k,v in event_code_count_dict.items():\n                new_df_dict[g_session][k] = v\n\n            for i in event_code_count_dict.keys():\n                 new_df_dict[g_session][i] = new_df[new_df['event_code'] == i]['event_code'].count()\n            #break\n    return new_df_dict\n        \no        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df:pd.DataFrame(),which):\n    \n    new_df_list_values = []\n    event_code_count_dict = {}\n    new_df_dict = {}\n    \n    for i in train['event_code'].unique().tolist():\n        event_code_count_dict[i] = 0\n        \n    df = df.reset_index(drop= False)\n    df.drop(columns=['index'],axis=1,inplace=True)\n    \n    a1 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'first').index.tolist()\n    a2 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'last').index.tolist()\n    \n    a = []\n    a.append(0)\n    for i in range(len(a2)):\n        a.append(a2[i])\n        a.append(a2[i]+1)\n    a.pop(len(a)-1)\n    \n    for i in tqdm(range(len(a))):\n        new_df = df.iloc[a[i]:a[i+1],:]\n        ids  = new_df['installation_id'].unique().tolist()[-1]\n        new_df_dict[ids] = {}\n        new_df_dict['num_game_session'] = new_df['game_session'].nunique()\n        new_df_dict['num_event_id'] = new_df['event_id'].nunique()\n        new_df_dict['num_actions_before_assessment'] = len(new_df['event_code'])\n        new_df_dict[f'num_unique_{which}'] = new_df[new_df['type'] == which]['title'].nunique()\n        if(which == 'Game'):\n            new_df_dict['game_attempts'] = new_df[new_df['event_code'] == 4020]['event_code'].count()\n            new_df_dict['mean_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].mean()\n            new_df_dict['max_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].max()\n            new_df_dict['min_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].min()\n            new_df_dict['std_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].std()\n            new_df['gaming_accuracy'] = new_df[(new_df['type'] == 'Game') & (new_df['event_code'] == 4020)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')) else 0)\n            new_df['gaming_accuracy'].fillna(0,inplace=True)\n            new_df_dict['gaming_accuracy'] = new_df['gaming_accuracy'].sum()/new_df_dict['game_attempts']\n            #new_df['time_gap_before_assessment'] = new_df['']\n        elif(which == 'Activity'):\n            new_df_dict['Activity actions'] = new_df[new_df['type'] == 'Activity']['event_id'].count()\n        \n        event_code_count_dict.update(new_df_dict)\n        break\n    print(event_code_count_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df:pd.DataFrame(),which):\n    \n    new_df_list_values = []\n    event_code_count_dict = {eve : 0 for eve in list_of_event_code}\n    new_df_dict = {}\n        \n    df = df.reset_index(drop= False)\n    df.drop(columns=['index'],axis=1,inplace=True)\n    \n    a1 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'first').index.tolist()\n    a2 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'last').index.tolist()\n    \n    a = []\n    a.append(0)\n    for i in range(len(a2)):\n        a.append(a2[i])\n        a.append(a2[i]+1)\n    a.pop(len(a)-1)\n    \n    for i in tqdm(range(10)):\n        new_df = df.iloc[a[i]:a[i+1],:]\n        ids  = new_df['installation_id'].unique().tolist()[-1]\n        g_session = new_df[new_df['type'] == 'Assessment']['game_session'].unique()[-1]\n        print(ids,g_session)\n        new_df_dict[ids] = {}\n        new_df_dict[ids][g_session] = {}\n        new_df_dict[ids][g_session]['num_game_session'] = new_df['game_session'].nunique()\n        new_df_dict[ids][g_session]['num_event_id'] = new_df['event_id'].nunique()\n        new_df_dict[ids][g_session]['num_actions_before_assessment'] = len(new_df['event_code'])\n        new_df_dict[ids][g_session][f'num_unique_{which}'] = new_df[new_df['type'] == which]['title'].nunique()\n        if(which == 'Game'):\n            new_df_dict[ids][g_session]['game_attempts'] = new_df[new_df['event_code'] == 4020]['event_code'].count()\n            new_df_dict[ids][g_session]['mean_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].mean()\n            new_df_dict[ids][g_session]['max_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].max()\n            new_df_dict[ids][g_session]['min_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].min()\n            new_df_dict[ids][g_session]['std_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].std()\n            new_df['gaming_accuracy'] = new_df[(new_df['type'] == 'Game') & (new_df['event_code'] == 4020)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')) else 0)\n            new_df['gaming_accuracy'].fillna(0,inplace=True)\n            new_df_dict[ids][g_session]['gaming_accuracy'] = new_df['gaming_accuracy'].sum()/new_df_dict[ids][g_session]['game_attempts']\n        elif(which == 'Activity'):\n            new_df_dict[ids][g_session]['Activity actions'] = new_df[new_df['type'] == 'Activity']['event_id'].count()\n        \n        for k,v in event_code_count_dict.items():\n            new_df_dict[ids][g_session][k] = v\n        \n        for i in event_code_count_dict.keys():\n             new_df_dict[ids][g_session][i] = new_df[new_df['event_code'] == i]['event_code'].count()\n        #break\n    return new_df_dict\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_column_values = {}\nfor i in tqdm(train['installation_id'].unique().tolist()):\n    df = train[(train['installation_id'] == i) & ((train['type'] == 'Game') | (train['type'] == 'Assessment'))]\n    column_values_instance = get_features(df,'Game')\n    train_column_values.update(column_values_instance)\ntrain_column_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"per_install_id_features = {}\nevent_code_count_per_id = {}\nfor i,data in tqdm(train.groupby('installation_id',sort = False)):\n    new_data = data[data.columns.tolist()]\n    per_install_id_features[i] = {}\n    for j in ['Game','Activity','Clip']:\n        per_install_id_features[i][f'num_{j}'] = new_data[new_data['type'] == j]['title'].nunique()\n    per_install_id_features[i]['total_num_actions'] = new_data[(new_data['type'] == 'Game') | (new_data['type'] == 'Activity') | (new_data['type'] == 'Clip')]['event_id'].count()\n    per_install_id_features[i]['total_game_attempts'] = new_data[(new_data['type'] == 'Game') & (new_data['event_code'] == 4020)]['event_code'].count()\n    new_data['correct_attempts'] = new_data[(new_data['type'] == 'Game') & (new_data['event_code'] == 4020)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true'))>=0 else 0)\n    per_install_id_features[i]['total_correct_game_attempts'] = new_data['correct_attempts'].sum()\n    per_install_id_features[i]['total_accuracy'] = per_install_id_features[i]['total_correct_game_attempts']/per_install_id_features[i]['total_game_attempts'] if per_install_id_features[i]['total_game_attempts'] >0 else 0\n    \nper_install_id_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clip_features = ['num_clip_watched']\ngame_features = ['num_unique_games','total_game_actions','total_duration_spend_for_game','total_game_attempts','total_correct_attempts','last_game_played_accuracy','gaming_accuracy']\nactivity_features = []\ntotal_data = {}\n\nfor i,install_id in tqdm(test.groupby('installation_id',sort=False)):\n    \n    clip_data = {eve : 0 for eve in clip_features}\n    game_data = {eve : 0 for eve in game_features}\n    activity_data = {}\n    event_code_count = {eve : 0 for eve in list_of_event_code}\n    \n    for j,session in install_id.groupby('game_session',sort=False):\n        \n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        \n        if((session_type == 'Clip')):\n            clip_data['num_clip_watched'] += 1\n            \n        elif(session_type == 'Game'):\n            game_data['num_unique_games'] += 1\n            game_data['total_game_actions'] += session['event_code'].count()\n            game_data['total_duration_spend_for_game'] += int(session['game_time'].iloc[-1]/1000)\n            game_data['total_game_attempts'] += session[session['event_code'] == 4020]['event_code'].count()\n            game_data['total_correct_attempts'] += session[session['event_code'] == 4020]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true') >= 0) else 0).sum()\n            game_data['gaming_accuracy'] += np.round((game_data['total_correct_attempts']/game_data['total_game_attempts']),3)\n            game_data['last_game_played_accuracy'] = np.round(game_data['total_correct_attempts'] / game_data['total_game_attempts'],3) if(game_data['total_game_attempts']>0) else 0\n        elif(session_type == 'Activity'):\n            pass\n        elif(session_type == 'Assessment'):\n            #game_preprocessing\n            \n            \n            #Activity preprocessing\n            \n            \n            #Clip preprocessing\n            \n            \n            \n            total_data[j] = {}\n            total_data[j].update(clip_data)\n            total_data[j].update(activity_data)\n            total_data[j].update(game_data)\n            \n            clip_data = {eve : 0 for eve in clip_features}\n            game_data = {eve : 0 for eve in game_features}\n            activity_data = {}\n    #break   \n            \ntotal_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[(train['type'] == 'Assessment') & (((train['event_code'] == 4100) & (train['title'] != 'Bird Measurer (Assessment)')) | ((train['event_code'] == 4110) & (train['title'] == 'Bird Measurer (Assessment)')))]\n\nsession_count = train['game_session'].value_counts().to_dict()\ntrain['assessment_attempt_count'] = train['game_session'].map(session_count)\n\ntrain['contains_true_assessment'] = train['event_data'].map(lambda x: True if (x.find('\"correct\":true')>=0) else False)\n\nchange_value = {\n    True : 1,\n    False : 0\n}\ntrain['contains_true_assessment'] = train['contains_true_assessment'].map(change_value)\n\ncorrect_attempt = dict(train.groupby('game_session',sort=False)['contains_true_assessment'].sum())\ntrain['contains_true_assessment_count'] = train['game_session'].map(correct_attempt)\n\nfor c in ['contains_true_assessment']:\n    train.pop(c)\n    \ntrain['accumulated_accuracy'] = np.where((train['contains_true_assessment_count'] == 0),0,(train['contains_true_assessment_count']/train['assessment_attempt_count']))\n\ntrain.loc[(train['type'] == 'Assessment'), 'accuracy_group'] = 0\ntrain.loc[(train['accumulated_accuracy'] == 1) & (train['type'] == 'Assessment'), 'accuracy_group'] = 3\ntrain.loc[(train['accumulated_accuracy'] == 0.5) & (train['type'] == 'Assessment'), 'accuracy_group'] = 2\ntrain.loc[(train['accumulated_accuracy'] < 0.5) & (train['accumulated_accuracy'] > 0) & (train['assessment_attempt_count'] > 0) & (train['type'] == 'Assessment'), 'accuracy_group'] = 1\n\ntrain.rename(columns = {'contains_true_assessment_count': 'num_correct',\n                        'accumulated_accuracy':'accuracy',\n                        'assessment_attempt_count': 'total_attempt'},inplace=True)\ntrain = train.drop_duplicates(subset = 'game_session',keep = 'last')\ntrain = train.reset_index(drop=False)\ntrain.drop(columns = ['index'],axis = 1, inplace = True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test =  test[(test['type'] == 'Assessment') &  ((test['event_count'] == 1) | ((test['event_code'] == 4100) & (test['title'] != 'Bird Measurer (Assessment)')) | ((test['event_code'] == 4110) & (test['title'] == 'Bird Measurer (Assessment)')))]\nsession_count = test['game_session'].value_counts().to_dict()\ntest['assessment_attempt_count'] = test['game_session'].map(session_count)\n\ntest['contains_true_assessment'] = test['event_data'].map(lambda x: True if (x.find('\"correct\":true')>=0) else False)\n\nchange_value = {\n    True : 1,\n    False : 0\n}\ntest['contains_true_assessment'] = test['contains_true_assessment'].map(change_value)\n\ncorrect_attempt = dict(test.groupby('game_session',sort=False)['contains_true_assessment'].sum())\ntest['contains_true_assessment_count'] = test['game_session'].map(correct_attempt)\n\n\nfor c in ['contains_true_assessment']:\n    test.pop(c)\n\ntest['accumulated_accuracy'] = np.where((test['contains_true_assessment_count'] == 0),0,(test['contains_true_assessment_count']/test['assessment_attempt_count']))\n\ntest.loc[(test['type'] == 'Assessment'), 'accuracy_group'] = 0\ntest.loc[(test['accumulated_accuracy'] == 1) & (test['type'] == 'Assessment'), 'accuracy_group'] = 3\ntest.loc[(test['accumulated_accuracy'] == 0.5) & (test['type'] == 'Assessment'), 'accuracy_group'] = 2\ntest.loc[(test['accumulated_accuracy'] < 0.5) & (test['accumulated_accuracy'] > 0) & (test['assessment_attempt_count'] > 0) & (test['type'] == 'Assessment'), 'accuracy_group'] = 1\n\ntest.rename(columns = {'contains_true_assessment_count': 'num_correct',\n                        'accumulated_accuracy':'accuracy',\n                        'assessment_attempt_count': 'total_attempt'},inplace=True)\n\ntest = test.drop_duplicates(subset = 'game_session',keep = 'last')\ntest = test.reset_index(drop=False)\ntest.drop(columns = ['index'],axis = 1, inplace = True)\ntest.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}