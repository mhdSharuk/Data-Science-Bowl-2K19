{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows',None)\npd.set_option('display.max_columns', None)\nimport datetime\nimport catboost\nfrom catboost import CatBoostClassifier,Pool\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nimport os\nimport random\nimport itertools\nimport json\nimport pprint\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold,GroupKFold\nfrom sklearn.metrics import confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import cohen_kappa_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def qwk(a1, a2, max_rat=3):\n    assert(len(a1) == len(a2))\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spec(value,*args):\n    i= specs[specs['event_id'] == value].index.values[-1]\n    print('Index :',i)\n    print('Event_code :',train[train['event_id'] == value]['event_code'].unique()[-1])\n    for arg in args:\n        if(arg == 'info'):\n         print(specs[arg][i])\n        elif(arg == 'args'):\n         print(pprint.pprint(json.loads(specs[arg][i])))\n        else:\n         print('Nothing')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def event(value):\n    i = train[train['event_id'] == value].index.values[-1]\n    print(pprint.pprint(json.loads(train['event_data'][i])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_game_feature(df,data):\n    g0_d = dict(df[df['type'] == 'Game'].groupby('installation_id')['type'].value_counts())\n    g0 = {}\n    for (k,i),v in g0_d.items():\n        g0[k] = v\n    del g0_d\n    df['G0'] = df['installation_id'].map(g0)\n    df['G0'].fillna(0,inplace=True)\n\n    g1_d = dict(df[(df['event_code'] == 4020) & (df['type'] == 'Game')].groupby('installation_id')['event_code'].value_counts())\n    g1 = {}\n    for (k,i),v in g1_d.items():\n        g1[k] = v\n    del g1_d\n    df['G1'] = df['installation_id'].map(g1)\n    df['G1'].fillna(0,inplace=True)\n    del g1\n    \n    df['contains_true'] = df[(df['event_code'] == 4020) & (df['type'] == 'Game')]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')>= 0) else 0)\n    g2 = dict(df[df['event_code'] == 4020].groupby('installation_id')['contains_true'].sum())\n    df['G2'] = df['installation_id'].map(g2)\n    df['G2'].fillna(0,inplace=True)\n    for c in ['contains_true']:\n        df.pop(c)\n        \n    df['G3'] = df['G2'] / df['G1']\n    df['G3'] = df['G3'].map(lambda x:3 if(x == 1.0) else(2 if((x >= 0.5) & (x <1.0)) else (1 if((x>0.0) &  (x<0.5)) else 0)))\n    df['G3'].fillna(0,inplace=True)\n    \n    i = 4\n    for d in tqdm(data):\n        g_attempt_d = dict(df[(df['type'] == 'Game') & (df['event_code'] == 4020) & (df['title'] == d)].groupby('installation_id')['title'].value_counts())\n        g_attempt = {}\n        for (k,z),v in g_attempt_d.items():\n            g_attempt[k] = v\n\n        df[f'G{i}_attempt'] = df['installation_id'].map(g_attempt)\n        df[f'G{i}_attempt'].fillna(0,inplace=True)\n\n        df['contains_true'] = df[(df['type'] == 'Game') & (df['event_code'] == 4020) & (df['title'] == d)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')>=0) else 0)\n        g = dict(df.groupby('installation_id')['contains_true'].sum())\n        df[f'G{i}_correct'] = df['installation_id'].map(g)\n        df[f'G{i}_correct'].fillna(0,inplace=True)\n\n        df[f'G{i}_accuracy'] = df[f'G{i}_correct'] / df[f'G{i}_attempt']\n        df[f'G{i}_accuracy'] = df[f'G{i}_accuracy'].map(lambda x:3 if(x == 1.0) else(2 if((x >= 0.5) & (x <1.0)) else (1 if((x>0.0) &  (x<0.5)) else 0)))\n        df[f'G{i}_accuracy'].fillna(0,inplace=True)\n\n        for c in ['contains_true',f'G{i}_attempt']:\n            df.pop(c)\n            \n        i = i + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_attempted_assessment_results(df,data):\n    if(data == 'train'):\n        df = df[(df['type'] == 'Assessment') & (((df['event_code'] == 4100) & (df['title'] != 'Bird Measurer (Assessment)')) | ((df['event_code'] == 4110) & (df['title'] == 'Bird Measurer (Assessment)')))]\n    else:\n        df =  df[(df['type'] == 'Assessment') &  ((df['event_count'] == 1) | ((df['event_code'] == 4100) & (df['title'] != 'Bird Measurer (Assessment)')) | ((df['event_code'] == 4110) & (df['title'] == 'Bird Measurer (Assessment)')))]\n    session_count = df['game_session'].value_counts().to_dict()\n    df['assessment_attempt_count'] = df['game_session'].map(session_count)\n\n    df['contains_true_assessment'] = df['event_data'].map(lambda x: True if (x.find('\"correct\":true')>=0) else False)\n\n    change_value = {\n        True : 1,\n        False : 0\n    }\n    df['contains_true_assessment'] = df['contains_true_assessment'].map(change_value)\n\n    correct_attempt = dict(df.groupby('game_session',sort=False)['contains_true_assessment'].sum())\n    df['contains_true_assessment_count'] = df['game_session'].map(correct_attempt)\n\n    for c in ['contains_true_assessment']:\n        df.pop(c)\n\n    df['accumulated_accuracy'] = np.where((df['contains_true_assessment_count'] == 0),0,(df['contains_true_assessment_count']/df['assessment_attempt_count']))\n\n    df.loc[(df['type'] == 'Assessment'), 'accuracy_group'] = 0\n    df.loc[(df['accumulated_accuracy'] == 1) & (df['type'] == 'Assessment'), 'accuracy_group'] = 3\n    df.loc[(df['accumulated_accuracy'] == 0.5) & (df['type'] == 'Assessment'), 'accuracy_group'] = 2\n    df.loc[(df['accumulated_accuracy'] < 0.5) & (df['accumulated_accuracy'] > 0) & (df['assessment_attempt_count'] > 0) & (df['type'] == 'Assessment'), 'accuracy_group'] = 1\n\n    df.rename(columns = {'contains_true_assessment_count': 'num_correct',\n                            'accumulated_accuracy':'accuracy',\n                            'assessment_attempt_count': 'total_attempt'},inplace=True)\n    df = df.drop_duplicates(subset = 'game_session',keep = 'last')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_validation_data(df,num_samples,random_state):\n    validation_data = df[(df['type'] == 'Assessment') & (((df['event_code'] == 4100) & (df['title'] != 'Bird Measurer (Assessment)')) | ((df['event_code'] == 4110) & (df['title'] == 'Bird Measurer (Assessment)')))]\n    validation_data.drop_duplicates(subset = 'game_session',keep = 'last',inplace=True)\n    if(isinstance(num_samples,float)):\n            validation_data = validation_data.sample(frac = num_samples,random_state = random_state)\n            print(validation_data.shape)\n    else:\n            validation_data = validation_data.sample(n = num_samples,random_state = random_state)\n            print(validation_data.shape)\n    return validation_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\ntrain = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\nsubmission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assessment_id = list(train[train['type'] == 'Assessment']['installation_id'].unique())\ntrain = train.loc[train['installation_id'].isin(assessment_id)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_train_game = train[(train['type'] == 'Assessment') & (((train['event_code'] == 4100) & (train['title'] != 'Bird Measurer (Assessment)')) | ((train['event_code'] == 4110) & (train['title'] == 'Bird Measurer (Assessment)')))]['game_session'].unique().tolist()\ntrain_game_session = train['game_session'].unique().tolist()\nnot_in_train_game = [x for x in train_game_session if x not in in_train_game]\nprint(len(in_train_game),len(train_game_session),len(not_in_train_game))\n\ntrain = train.loc[~train['game_session'].isin(not_in_train_game)]\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.reset_index(drop=False)\ntrain.drop(columns = ['index'],axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_event_code = set(train['event_code'].unique()).union(set(test['event_code'].unique()))\nlist_of_event_code = list(list_of_event_code)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = train.copy()\nb = a[a['type'] == 'Assessment']\nb = b.drop_duplicates(subset = 'installation_id',keep ='last').index.tolist()\na = a.drop_duplicates(subset = 'installation_id', keep = 'last').index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_game = train[(train['type'] == 'Game') | (train['type'] == 'Assessment')]\ntrain_activity = train[(train['type'] == 'Assessment') | (train['type'] == 'Activity')]\ntrain_clip = train[(train['type'] == 'Assessment') | (train['type'] == 'Clip')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df:pd.DataFrame(),which):\n    \n    new_df_list_values = []\n    event_code_count_dict = {eve : 0 for eve in list_of_event_code}\n    new_df_dict = {}\n        \n    df = df.reset_index(drop= False)\n    df.drop(columns=['index'],axis=1,inplace=True)\n    \n    for i,data in df.groupby('installation_id',sort=False):\n        new_data = data[df.columns.tolist()]\n        a1 = new_data[new_data['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'first').index.tolist()\n        a2 = new_data[new_data['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'last').index.tolist()\n\n        a = []\n        a.append(0)\n        print(len(a1),len(a2))\n        for i in range(len(a2)):\n            a.append(a2[i])\n            a.append(a2[i]+1)\n        #a.pop(len(a)-1)\n\n        for i in tqdm(range(0,len(a),2)):\n            new_df = data.iloc[a[i]:a[i+1],:]\n            g_session = new_df[new_df['type'] == 'Assessment']['game_session'].unique()[-1]\n            print(i,g_session)\n            new_df_dict[g_session] = {}\n            new_df_dict[g_session]['num_game_session'] = new_df['game_session'].nunique()\n            new_df_dict[g_session]['num_event_id'] = new_df['event_id'].nunique()\n            new_df_dict[g_session]['num_actions_before_assessment'] = len(new_df['event_code'])\n            new_df_dict[g_session][f'num_unique_{which}'] = new_df[new_df['type'] == which]['title'].nunique()\n            if(which == 'Game'):\n                new_df_dict[g_session]['game_attempts'] = new_df[new_df['event_code'] == 4020]['event_code'].count()\n                new_df_dict[g_session]['mean_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].mean()\n                new_df_dict[g_session]['max_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].max()\n                new_df_dict[g_session]['min_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].min()\n                new_df_dict[g_session]['std_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].std()\n                new_df['gaming_accuracy'] = new_df[(new_df['type'] == 'Game') & (new_df['event_code'] == 4020)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')) else 0)\n                new_df['gaming_accuracy'].fillna(0,inplace=True)\n                new_df_dict[g_session]['gaming_accuracy'] = new_df['gaming_accuracy'].sum()/new_df_dict[g_session]['game_attempts']\n            elif(which == 'Activity'):\n                new_df_dict[g_session]['Activity actions'] = new_df[new_df['type'] == 'Activity']['event_id'].count()\n\n            for k,v in event_code_count_dict.items():\n                new_df_dict[g_session][k] = v\n\n            for i in event_code_count_dict.keys():\n                 new_df_dict[g_session][i] = new_df[new_df['event_code'] == i]['event_code'].count()\n            #break\n    return new_df_dict\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = get_features(train_game,'Game')\ng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i , data in train.groupby('installation_id',sort = False):\n    new_data = data[train.columns.tolist()]\n    a1 = new_data[new_data['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'first').index.tolist()\n    a2 = new_data[new_data['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'last').index.tolist()\n    \n    a = []\n    a.append(0)\n    for i in range(len(a2)):\n        a.append(a2[i])\n        a.append(a2[i]+1)\n    a.pop(len(a)-1)\n    break\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For Game**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#game_list = set(train[train['type'] == 'Game']['title'].unique()).union(set(test[test['type'] == 'Game']['title'].unique()))\n#game_list = list(game_list)zzz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get_game_feature(train,game_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get_game_feature(test,game_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#activities_list = set(train[train['type'] == 'Activity']['title'].unique()).union(set(test[test['type'] == 'Activity']['title'].unique()))\n#activities_list = list(activities_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#assessment_list = set(train[train['type'] == 'Assessment']['title'].unique()).union(set(test[test['type'] == 'Assessment']['title'].unique()))\n#assessment_list = list(assessment_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[(train['type'] == 'Assessment') & (((train['event_code'] == 4100) & (train['title'] != 'Bird Measurer (Assessment)')) | ((train['event_code'] == 4110) & (train['title'] == 'Bird Measurer (Assessment)')))]\n\nsession_count = train['game_session'].value_counts().to_dict()\ntrain['assessment_attempt_count'] = train['game_session'].map(session_count)\n\ntrain['contains_true_assessment'] = train['event_data'].map(lambda x: True if (x.find('\"correct\":true')>=0) else False)\n\nchange_value = {\n    True : 1,\n    False : 0\n}\ntrain['contains_true_assessment'] = train['contains_true_assessment'].map(change_value)\n\ncorrect_attempt = dict(train.groupby('game_session',sort=False)['contains_true_assessment'].sum())\ntrain['contains_true_assessment_count'] = train['game_session'].map(correct_attempt)\n\nfor c in ['contains_true_assessment']:\n    train.pop(c)\n    \ntrain['accumulated_accuracy'] = np.where((train['contains_true_assessment_count'] == 0),0,(train['contains_true_assessment_count']/train['assessment_attempt_count']))\n\ntrain.loc[(train['type'] == 'Assessment'), 'accuracy_group'] = 0\ntrain.loc[(train['accumulated_accuracy'] == 1) & (train['type'] == 'Assessment'), 'accuracy_group'] = 3\ntrain.loc[(train['accumulated_accuracy'] == 0.5) & (train['type'] == 'Assessment'), 'accuracy_group'] = 2\ntrain.loc[(train['accumulated_accuracy'] < 0.5) & (train['accumulated_accuracy'] > 0) & (train['assessment_attempt_count'] > 0) & (train['type'] == 'Assessment'), 'accuracy_group'] = 1\n\ntrain.rename(columns = {'contains_true_assessment_count': 'num_correct',\n                        'accumulated_accuracy':'accuracy',\n                        'assessment_attempt_count': 'total_attempt'},inplace=True)\ntrain = train.drop_duplicates(subset = 'game_session',keep = 'last')\ntrain = train.reset_index(drop=False)\ntrain.drop(columns = ['index'],axis = 1, inplace = True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test =  test[(test['type'] == 'Assessment') &  ((test['event_count'] == 1) | ((test['event_code'] == 4100) & (test['title'] != 'Bird Measurer (Assessment)')) | ((test['event_code'] == 4110) & (test['title'] == 'Bird Measurer (Assessment)')))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"session_count = test['game_session'].value_counts().to_dict()\ntest['assessment_attempt_count'] = test['game_session'].map(session_count)\n\ntest['contains_true_assessment'] = test['event_data'].map(lambda x: True if (x.find('\"correct\":true')>=0) else False)\n\nchange_value = {\n    True : 1,\n    False : 0\n}\ntest['contains_true_assessment'] = test['contains_true_assessment'].map(change_value)\n\ncorrect_attempt = dict(test.groupby('game_session',sort=False)['contains_true_assessment'].sum())\ntest['contains_true_assessment_count'] = test['game_session'].map(correct_attempt)\n\n\nfor c in ['contains_true_assessment']:\n    test.pop(c)\n\ntest['accumulated_accuracy'] = np.where((test['contains_true_assessment_count'] == 0),0,(test['contains_true_assessment_count']/test['assessment_attempt_count']))\n\ntest.loc[(test['type'] == 'Assessment'), 'accuracy_group'] = 0\ntest.loc[(test['accumulated_accuracy'] == 1) & (test['type'] == 'Assessment'), 'accuracy_group'] = 3\ntest.loc[(test['accumulated_accuracy'] == 0.5) & (test['type'] == 'Assessment'), 'accuracy_group'] = 2\ntest.loc[(test['accumulated_accuracy'] < 0.5) & (test['accumulated_accuracy'] > 0) & (test['assessment_attempt_count'] > 0) & (test['type'] == 'Assessment'), 'accuracy_group'] = 1\n\ntest.rename(columns = {'contains_true_assessment_count': 'num_correct',\n                        'accumulated_accuracy':'accuracy',\n                        'assessment_attempt_count': 'total_attempt'},inplace=True)\n\ntest = test.drop_duplicates(subset = 'game_session',keep = 'last')\ntest = test.reset_index(drop=False)\ntest.drop(columns = ['index'],axis = 1, inplace = True)\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validation_data = get_validation_data(test,0.2,45)#\n#validation_data = validation_data.reset_index(drop=False)\n#validation_data.drop(columns = ['index'],axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validation_install_id = validation_data['installation_id'].unique().tolist()#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test = test.loc[~test['installation_id'].isin(validation_install_id)]#\n#test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in tqdm(['event_id','game_session','installation_id','event_code','event_data','event_count','type','timestamp','world']):\n    for df in [train,test]:\n        df.pop(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\nactivities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n\ntrain['title'] = train['title'].map(activities_map)\ntest['title'] = test['title'].map(activities_map)\ntrain_labels['title'] = train_labels['title'].map(activities_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#validation_data['title'] = validation_data['title'].map(activities_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train.drop(columns=['accuracy_group'],axis=1)\ny = train['accuracy_group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#val_x = validation_data.drop(columns=['accuracy_group'],axis=1)\n#val_y = validation_data['accuracy_group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_classifier():\n    clf = CatBoostClassifier(\n                               loss_function='MultiClass',\n                               task_type=\"CPU\",\n                               learning_rate=0.01,\n                               iterations=100,\n                               od_type=\"Iter\",\n                               early_stopping_rounds=50,\n                               random_seed=2019,\n                               colsample_bylevel=0.87,\n                               eval_metric='Kappa',\n                              )\n        \n    return clf\noof = np.zeros(len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y.head(10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(x))\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\n\n\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(x, y)):\n    \n    print(f'Training on fold {fold+1}')\n    clf = make_classifier()\n    clf.fit(x.loc[trn_idx], y.loc[trn_idx], eval_set=(x.loc[test_idx], y.loc[test_idx]),\n                          use_best_model=True, verbose=500)\n    \n    oof[test_idx] = clf.predict(x.loc[test_idx]).reshape(len(test_idx))\n    print('OOF QWK:', qwk(y, oof))\n    \nprint('-' * 30)\nprint('OOF QWK:', qwk(y, oof))\nprint('-' * 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['installation_id'] == '0006a69f']['world'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['installation_id'] == '0006a69f') & (train['type'] == 'Assessment')]['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['world'] == 'MAGMAPEAK') & (train['type'] == 'Game')]['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['world'] == 'MAGMAPEAK') & (train['type'] == 'Activity')]['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['world'] == 'MAGMAPEAK') & (train['type'] == 'Assessment')]['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = train.columns.tolist()\ncols.remove('installation_id')\nfor i ,data in train.groupby('installation_id',sort=False):\n    new_data = data[cols]\n    new_data['installation_id'] = i\n    break\nnew_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df:pd.DataFrame(),which):\n    \n    new_df_list_values = []\n    event_code_count_dict = {}\n    new_df_dict = {}\n    \n    for i in train['event_code'].unique().tolist():\n        event_code_count_dict[i] = 0\n        \n    df = df.reset_index(drop= False)\n    df.drop(columns=['index'],axis=1,inplace=True)\n    \n    a1 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'first').index.tolist()\n    a2 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'last').index.tolist()\n    \n    a = []\n    a.append(0)\n    for i in range(len(a2)):\n        a.append(a2[i])\n        a.append(a2[i]+1)\n    a.pop(len(a)-1)\n    \n    for i in tqdm(range(len(a))):\n        new_df = df.iloc[a[i]:a[i+1],:]\n        ids  = new_df['installation_id'].unique().tolist()[-1]\n        new_df_dict[ids] = {}\n        new_df_dict['num_game_session'] = new_df['game_session'].nunique()\n        new_df_dict['num_event_id'] = new_df['event_id'].nunique()\n        new_df_dict['num_actions_before_assessment'] = len(new_df['event_code'])\n        new_df_dict[f'num_unique_{which}'] = new_df[new_df['type'] == which]['title'].nunique()\n        if(which == 'Game'):\n            new_df_dict['game_attempts'] = new_df[new_df['event_code'] == 4020]['event_code'].count()\n            new_df_dict['mean_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].mean()\n            new_df_dict['max_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].max()\n            new_df_dict['min_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].min()\n            new_df_dict['std_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].std()\n            new_df['gaming_accuracy'] = new_df[(new_df['type'] == 'Game') & (new_df['event_code'] == 4020)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')) else 0)\n            new_df['gaming_accuracy'].fillna(0,inplace=True)\n            new_df_dict['gaming_accuracy'] = new_df['gaming_accuracy'].sum()/new_df_dict['game_attempts']\n            #new_df['time_gap_before_assessment'] = new_df['']\n        elif(which == 'Activity'):\n            new_df_dict['Activity actions'] = new_df[new_df['type'] == 'Activity']['event_id'].count()\n        \n        event_code_count_dict.update(new_df_dict)\n        break\n    print(event_code_count_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_features(df:pd.DataFrame(),which):\n    \n    new_df_list_values = []\n    event_code_count_dict = {eve : 0 for eve in list_of_event_code}\n    new_df_dict = {}\n        \n    df = df.reset_index(drop= False)\n    df.drop(columns=['index'],axis=1,inplace=True)\n    \n    a1 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'first').index.tolist()\n    a2 = df[df['type'] == 'Assessment'].drop_duplicates(subset = 'game_session',keep = 'last').index.tolist()\n    \n    a = []\n    a.append(0)\n    for i in range(len(a2)):\n        a.append(a2[i])\n        a.append(a2[i]+1)\n    a.pop(len(a)-1)\n    \n    for i in tqdm(range(2)):\n        new_df = df.iloc[a[i]:a[i+1],:]\n        ids  = new_df['installation_id'].unique().tolist()[-1]\n        g_session = new_df[new_df['type'] == 'Assessment']['game_session'].unique()[-1]\n        print(ids,g_session)\n        new_df_dict[ids] = {}\n        new_df_dict[ids][g_session] = {}\n        new_df_dict[ids][g_session]['num_game_session'] = new_df['game_session'].nunique()\n        new_df_dict[ids][g_session]['num_event_id'] = new_df['event_id'].nunique()\n        new_df_dict[ids][g_session]['num_actions_before_assessment'] = len(new_df['event_code'])\n        new_df_dict[ids][g_session][f'num_unique_{which}'] = new_df[new_df['type'] == which]['title'].nunique()\n        if(which == 'Game'):\n            new_df_dict[ids][g_session]['game_attempts'] = new_df[new_df['event_code'] == 4020]['event_code'].count()\n            new_df_dict[ids][g_session]['mean_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].mean()\n            new_df_dict[ids][g_session]['max_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].max()\n            new_df_dict[ids][g_session]['min_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].min()\n            new_df_dict[ids][g_session]['std_game_time'] = new_df[new_df['type'] == 'Game']['game_time'].std()\n            new_df['gaming_accuracy'] = new_df[(new_df['type'] == 'Game') & (new_df['event_code'] == 4020)]['event_data'].map(lambda x:1 if(str(x).find('\"correct\":true')) else 0)\n            new_df['gaming_accuracy'].fillna(0,inplace=True)\n            new_df_dict[ids][g_session]['gaming_accuracy'] = new_df['gaming_accuracy'].sum()/new_df_dict[ids][g_session]['game_attempts']\n        elif(which == 'Activity'):\n            new_df_dict[ids][g_session]['Activity actions'] = new_df[new_df['type'] == 'Activity']['event_id'].count()\n        \n        for k,v in event_code_count_dict.items():\n            new_df_dict[ids][g_session][k] = v\n        \n        for i in event_code_count_dict.keys():\n             new_df_dict[ids][g_session][i] = new_df[new_df['event_code'] == i]['event_code'].count()\n        #break\n    return new_df_dict\n        \n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}